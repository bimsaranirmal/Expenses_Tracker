{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "5d3a2d8d",
            "metadata": {},
            "source": [
                "# AI Anomaly Detection Training (Real Dataset)\n",
                "\n",
                "This notebook trains an **Isolation Forest** model to detect unusual spending patterns using the provided `personal_finance_tracker_dataset.csv`."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "68762e94",
            "metadata": {},
            "source": [
                "## 1. Setup and Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "096db05f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Libraries loaded successfully.\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.ensemble import IsolationForest\n",
                "import joblib\n",
                "import os\n",
                "import json\n",
                "\n",
                "print(\"Libraries loaded successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4b6f8f43",
            "metadata": {},
            "source": [
                "## 2. Load Dataset\n",
                "\n",
                "We use `category` and `monthly_expense_total` as features. We apply Label Encoding to the categories to make them numeric."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "21ac11d0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading dataset from personal_finance_tracker_dataset.csv...\n"
                    ]
                }
            ],
            "source": [
                "dataset_path = 'personal_finance_tracker_dataset.csv'\n",
                "\n",
                "if os.path.exists(dataset_path):\n",
                "    print(f\"Loading dataset from {dataset_path}...\")\n",
                "    full_df = pd.read_csv(dataset_path)\n",
                "    df = full_df[['category', 'monthly_expense_total']].copy()\n",
                "    df.columns = ['category', 'amount']\n",
                "else:\n",
                "    print(\"Error: personal_finance_tracker_dataset.csv not found!\")\n",
                "    # Stop execution if CSV is missing"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "115b99aa",
            "metadata": {},
            "source": [
                "## 3. Label Encoding\n",
                "\n",
                "We map each category string to a unique ID and save this mapping for the detection script."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "4058043a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Categories mapped: ['Investments', 'Healthcare', 'Groceries', 'Utilities', 'Transportation', 'Entertainment', 'Education', 'Insurance', 'Dining Out', 'Rent']\n",
                        "      category   amount  category_label\n",
                        "0  Investments  3212.07               0\n",
                        "1  Investments  3732.81               0\n",
                        "2   Healthcare  3335.58               1\n",
                        "3    Groceries  2327.59               2\n",
                        "4    Utilities  2182.58               3\n"
                    ]
                }
            ],
            "source": [
                "unique_categories = df['category'].unique().tolist()\n",
                "cat_to_id = {cat: i for i, cat in enumerate(unique_categories)}\n",
                "\n",
                "with open('category_mapping.json', 'w') as f:\n",
                "    json.dump(cat_to_id, f)\n",
                "\n",
                "df['category_label'] = df['category'].map(cat_to_id)\n",
                "print(f\"Categories mapped: {list(cat_to_id.keys())}\")\n",
                "print(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "33219b38",
            "metadata": {},
            "source": [
                "## 4. Train Isolation Forest\n",
                "\n",
                "The model learns the 'normal' distribution of spending for each category."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "004dc812",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model trained.\n"
                    ]
                }
            ],
            "source": [
                "model = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
                "model.fit(df[['category_label', 'amount']])\n",
                "\n",
                "print(\"Model trained.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b2825d33",
            "metadata": {},
            "source": [
                "## 5. Test Anomaly Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "2c7cce62",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "        category  amount is_anomaly\n",
                        "0      Groceries    2000         NO\n",
                        "1      Groceries  500000        YES\n",
                        "2           Rent   50000        YES\n",
                        "3  Entertainment  250000        YES\n"
                    ]
                }
            ],
            "source": [
                "test_data = pd.DataFrame([\n",
                "    ['Groceries', 2000],    # Likely normal\n",
                "    ['Groceries', 500000],  # SUSPICIOUS (Too high)\n",
                "    ['Rent', 50000],        # Likely normal\n",
                "    ['Entertainment', 250000] # SUSPICIOUS (Too high)\n",
                "], columns=['category', 'amount'])\n",
                "\n",
                "test_data['category_label'] = test_data['category'].map(cat_to_id)\n",
                "predictions = model.predict(test_data[['category_label', 'amount']])\n",
                "test_data['is_anomaly'] = ['YES' if p == -1 else 'NO' for p in predictions]\n",
                "\n",
                "print(test_data[['category', 'amount', 'is_anomaly']])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "53b71af6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Overall Accuracy: 75.00%\n",
                        "\n",
                        "Detailed Classification Report:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "          NO       1.00      0.50      0.67         2\n",
                        "         YES       0.67      1.00      0.80         2\n",
                        "\n",
                        "    accuracy                           0.75         4\n",
                        "   macro avg       0.83      0.75      0.73         4\n",
                        "weighted avg       0.83      0.75      0.73         4\n",
                        "\n",
                        "\n",
                        "Confusion Matrix:\n",
                        "[[1 1]\n",
                        " [0 2]]\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "\n",
                "# 1. Define the Ground Truth (What the answer SHOULD be)\n",
                "# Based on your test_data logic: \n",
                "# [2000 is Normal, 500000 is Anomaly, 50000 is Normal, 250000 is Anomaly]\n",
                "true_labels = ['NO', 'YES', 'NO', 'YES'] \n",
                "\n",
                "# 2. Add them to your DataFrame for comparison\n",
                "test_data['actual'] = true_labels\n",
                "\n",
                "# 3. Calculate \"Accuracy\"\n",
                "# This is the percentage of total guesses that were correct\n",
                "acc = accuracy_score(test_data['actual'], test_data['is_anomaly'])\n",
                "\n",
                "# 4. Generate a detailed report\n",
                "# This shows Precision (how many 'YES' were correct) \n",
                "# and Recall (how many 'YES' did we miss)\n",
                "report = classification_report(test_data['actual'], test_data['is_anomaly'])\n",
                "\n",
                "print(f\"Overall Accuracy: {acc * 100:.2f}%\")\n",
                "print(\"\\nDetailed Classification Report:\")\n",
                "print(report)\n",
                "\n",
                "# 5. Visualizing the Confusion Matrix (Optional but recommended)\n",
                "print(\"\\nConfusion Matrix:\")\n",
                "print(confusion_matrix(test_data['actual'], test_data['is_anomaly'], labels=['NO', 'YES']))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "707d8fe2",
            "metadata": {},
            "source": [
                "## 6. Export Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "baab70ec",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model saved as anomaly_model.pkl\n"
                    ]
                }
            ],
            "source": [
                "joblib.dump(model, 'anomaly_model.pkl')\n",
                "print(\"Model saved as anomaly_model.pkl\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
