{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "3eff6fd5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\BIMSARA\\anaconda3\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
                        "  if not hasattr(np, \"object\"):\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense, Dropout\n",
                "from tensorflow.keras.callbacks import EarlyStopping\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "import joblib\n",
                "import os"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>date</th>\n",
                            "      <th>user_id</th>\n",
                            "      <th>monthly_income</th>\n",
                            "      <th>monthly_expense_total</th>\n",
                            "      <th>savings_rate</th>\n",
                            "      <th>budget_goal</th>\n",
                            "      <th>financial_scenario</th>\n",
                            "      <th>credit_score</th>\n",
                            "      <th>debt_to_income_ratio</th>\n",
                            "      <th>loan_payment</th>\n",
                            "      <th>...</th>\n",
                            "      <th>discretionary_spending</th>\n",
                            "      <th>essential_spending</th>\n",
                            "      <th>income_type</th>\n",
                            "      <th>rent_or_mortgage</th>\n",
                            "      <th>category</th>\n",
                            "      <th>cash_flow_status</th>\n",
                            "      <th>financial_advice_score</th>\n",
                            "      <th>financial_stress_level</th>\n",
                            "      <th>actual_savings</th>\n",
                            "      <th>savings_goal_met</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>2019-01-01</td>\n",
                            "      <td>1584</td>\n",
                            "      <td>3119.58</td>\n",
                            "      <td>3212.07</td>\n",
                            "      <td>0.38</td>\n",
                            "      <td>3676.11</td>\n",
                            "      <td>inflation</td>\n",
                            "      <td>721.0</td>\n",
                            "      <td>0.56</td>\n",
                            "      <td>125.77</td>\n",
                            "      <td>...</td>\n",
                            "      <td>857.55</td>\n",
                            "      <td>1910.85</td>\n",
                            "      <td>Freelance</td>\n",
                            "      <td>1501.65</td>\n",
                            "      <td>Investments</td>\n",
                            "      <td>Positive</td>\n",
                            "      <td>8.3</td>\n",
                            "      <td>Low</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2019-01-31</td>\n",
                            "      <td>1045</td>\n",
                            "      <td>3262.44</td>\n",
                            "      <td>3732.81</td>\n",
                            "      <td>0.10</td>\n",
                            "      <td>2607.17</td>\n",
                            "      <td>inflation</td>\n",
                            "      <td>670.0</td>\n",
                            "      <td>0.42</td>\n",
                            "      <td>454.19</td>\n",
                            "      <td>...</td>\n",
                            "      <td>534.51</td>\n",
                            "      <td>3165.20</td>\n",
                            "      <td>Salary</td>\n",
                            "      <td>1603.17</td>\n",
                            "      <td>Investments</td>\n",
                            "      <td>Positive</td>\n",
                            "      <td>22.6</td>\n",
                            "      <td>Low</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2019-03-02</td>\n",
                            "      <td>1756</td>\n",
                            "      <td>2931.20</td>\n",
                            "      <td>3335.58</td>\n",
                            "      <td>0.15</td>\n",
                            "      <td>3004.14</td>\n",
                            "      <td>inflation</td>\n",
                            "      <td>691.0</td>\n",
                            "      <td>0.24</td>\n",
                            "      <td>971.82</td>\n",
                            "      <td>...</td>\n",
                            "      <td>353.67</td>\n",
                            "      <td>1504.56</td>\n",
                            "      <td>Freelance</td>\n",
                            "      <td>1097.82</td>\n",
                            "      <td>Healthcare</td>\n",
                            "      <td>Positive</td>\n",
                            "      <td>58.8</td>\n",
                            "      <td>Low</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>2019-04-01</td>\n",
                            "      <td>1724</td>\n",
                            "      <td>3506.79</td>\n",
                            "      <td>2327.59</td>\n",
                            "      <td>0.17</td>\n",
                            "      <td>3346.97</td>\n",
                            "      <td>normal</td>\n",
                            "      <td>717.0</td>\n",
                            "      <td>0.16</td>\n",
                            "      <td>482.76</td>\n",
                            "      <td>...</td>\n",
                            "      <td>594.08</td>\n",
                            "      <td>1450.72</td>\n",
                            "      <td>Freelance</td>\n",
                            "      <td>1155.64</td>\n",
                            "      <td>Groceries</td>\n",
                            "      <td>Positive</td>\n",
                            "      <td>74.5</td>\n",
                            "      <td>Low</td>\n",
                            "      <td>1179.20</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2019-05-01</td>\n",
                            "      <td>1600</td>\n",
                            "      <td>4606.87</td>\n",
                            "      <td>2182.58</td>\n",
                            "      <td>0.34</td>\n",
                            "      <td>2670.09</td>\n",
                            "      <td>inflation</td>\n",
                            "      <td>795.0</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>263.74</td>\n",
                            "      <td>...</td>\n",
                            "      <td>556.86</td>\n",
                            "      <td>1000.00</td>\n",
                            "      <td>Salary</td>\n",
                            "      <td>1170.86</td>\n",
                            "      <td>Utilities</td>\n",
                            "      <td>Negative</td>\n",
                            "      <td>38.7</td>\n",
                            "      <td>High</td>\n",
                            "      <td>2424.29</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 25 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "         date  user_id  monthly_income  monthly_expense_total  savings_rate  \\\n",
                            "0  2019-01-01     1584         3119.58                3212.07          0.38   \n",
                            "1  2019-01-31     1045         3262.44                3732.81          0.10   \n",
                            "2  2019-03-02     1756         2931.20                3335.58          0.15   \n",
                            "3  2019-04-01     1724         3506.79                2327.59          0.17   \n",
                            "4  2019-05-01     1600         4606.87                2182.58          0.34   \n",
                            "\n",
                            "   budget_goal financial_scenario  credit_score  debt_to_income_ratio  \\\n",
                            "0      3676.11          inflation         721.0                  0.56   \n",
                            "1      2607.17          inflation         670.0                  0.42   \n",
                            "2      3004.14          inflation         691.0                  0.24   \n",
                            "3      3346.97             normal         717.0                  0.16   \n",
                            "4      2670.09          inflation         795.0                  0.25   \n",
                            "\n",
                            "   loan_payment  ...  discretionary_spending  essential_spending  income_type  \\\n",
                            "0        125.77  ...                  857.55             1910.85    Freelance   \n",
                            "1        454.19  ...                  534.51             3165.20       Salary   \n",
                            "2        971.82  ...                  353.67             1504.56    Freelance   \n",
                            "3        482.76  ...                  594.08             1450.72    Freelance   \n",
                            "4        263.74  ...                  556.86             1000.00       Salary   \n",
                            "\n",
                            "   rent_or_mortgage     category  cash_flow_status  financial_advice_score  \\\n",
                            "0           1501.65  Investments          Positive                     8.3   \n",
                            "1           1603.17  Investments          Positive                    22.6   \n",
                            "2           1097.82   Healthcare          Positive                    58.8   \n",
                            "3           1155.64    Groceries          Positive                    74.5   \n",
                            "4           1170.86    Utilities          Negative                    38.7   \n",
                            "\n",
                            "  financial_stress_level  actual_savings savings_goal_met  \n",
                            "0                    Low            0.00                0  \n",
                            "1                    Low            0.00                0  \n",
                            "2                    Low            0.00                0  \n",
                            "3                    Low         1179.20                0  \n",
                            "4                   High         2424.29                0  \n",
                            "\n",
                            "[5 rows x 25 columns]"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 1. Load the dataset\n",
                "df = pd.read_csv('personal_finance_tracker_dataset.csv')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>user_id</th>\n",
                            "      <th>month</th>\n",
                            "      <th>monthly_expense_total</th>\n",
                            "      <th>monthly_income</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1000</td>\n",
                            "      <td>2019-09</td>\n",
                            "      <td>4718.17</td>\n",
                            "      <td>3374.92</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1000</td>\n",
                            "      <td>2020-02</td>\n",
                            "      <td>2088.04</td>\n",
                            "      <td>3381.06</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1000</td>\n",
                            "      <td>2022-09</td>\n",
                            "      <td>2400.73</td>\n",
                            "      <td>2532.54</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1001</td>\n",
                            "      <td>2019-05</td>\n",
                            "      <td>1671.02</td>\n",
                            "      <td>4301.38</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1001</td>\n",
                            "      <td>2019-12</td>\n",
                            "      <td>4082.16</td>\n",
                            "      <td>5343.85</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>1001</td>\n",
                            "      <td>2020-07</td>\n",
                            "      <td>2119.47</td>\n",
                            "      <td>3542.30</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>1002</td>\n",
                            "      <td>2020-04</td>\n",
                            "      <td>2307.90</td>\n",
                            "      <td>4712.63</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>1003</td>\n",
                            "      <td>2021-11</td>\n",
                            "      <td>3552.34</td>\n",
                            "      <td>3465.95</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>1003</td>\n",
                            "      <td>2021-12</td>\n",
                            "      <td>3222.00</td>\n",
                            "      <td>4757.29</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>1003</td>\n",
                            "      <td>2022-01</td>\n",
                            "      <td>2797.07</td>\n",
                            "      <td>4873.11</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   user_id    month  monthly_expense_total  monthly_income\n",
                            "0     1000  2019-09                4718.17         3374.92\n",
                            "1     1000  2020-02                2088.04         3381.06\n",
                            "2     1000  2022-09                2400.73         2532.54\n",
                            "3     1001  2019-05                1671.02         4301.38\n",
                            "4     1001  2019-12                4082.16         5343.85\n",
                            "5     1001  2020-07                2119.47         3542.30\n",
                            "6     1002  2020-04                2307.90         4712.63\n",
                            "7     1003  2021-11                3552.34         3465.95\n",
                            "8     1003  2021-12                3222.00         4757.29\n",
                            "9     1003  2022-01                2797.07         4873.11"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 2. Prepare Data (Aggregation and Sequence Creation)\n",
                "# We group by user and month to get monthly totals, then create a sliding window of 3 months.\n",
                "\n",
                "df['date'] = pd.to_datetime(df['date'])\n",
                "df['month'] = df['date'].dt.to_period('M')\n",
                "\n",
                "monthly_data = df.groupby(['user_id', 'month'])[['monthly_expense_total', 'monthly_income']].sum().reset_index()\n",
                "monthly_data = monthly_data.sort_values(['user_id', 'month'])\n",
                "monthly_data.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Expense sequences: 601\n",
                        "Income sequences: 601\n"
                    ]
                }
            ],
            "source": [
                "def create_sequences(data, target_col, window_size=3):\n",
                "    X, y = [], []\n",
                "    for user in data['user_id'].unique():\n",
                "        user_data = data[data['user_id'] == user][target_col].values\n",
                "        if len(user_data) > window_size:\n",
                "            for i in range(len(user_data) - window_size):\n",
                "                X.append(user_data[i:i+window_size])\n",
                "                y.append(user_data[i+window_size])\n",
                "    return np.array(X), np.array(y)\n",
                "\n",
                "X_exp, y_exp = create_sequences(monthly_data, 'monthly_expense_total')\n",
                "X_inc, y_inc = create_sequences(monthly_data, 'monthly_income')\n",
                "\n",
                "print(f\"Expense sequences: {len(X_exp)}\")\n",
                "print(f\"Income sequences: {len(X_inc)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Scalers saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "# 3. Scaling Data (Critical for Deep Learning)\n",
                "scaler_exp = StandardScaler()\n",
                "X_exp_scaled = scaler_exp.fit_transform(X_exp)\n",
                "\n",
                "scaler_inc = StandardScaler()\n",
                "X_inc_scaled = scaler_inc.fit_transform(X_inc)\n",
                "\n",
                "# Save scalers for prediction\n",
                "joblib.dump(scaler_exp, 'scaler_expense.pkl')\n",
                "joblib.dump(scaler_inc, 'scaler_income.pkl')\n",
                "\n",
                "print(\"Scalers saved successfully.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\BIMSARA\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
                        "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training Expense Model...\n",
                        "Epoch 1/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 10549877.0000 - mae: 3099.8259 - val_loss: 11293501.0000 - val_mae: 3179.1538\n",
                        "Epoch 2/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 10548478.0000 - mae: 3099.6003 - val_loss: 11291922.0000 - val_mae: 3178.9021\n",
                        "Epoch 3/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 10546630.0000 - mae: 3099.3032 - val_loss: 11289138.0000 - val_mae: 3178.4512\n",
                        "Epoch 4/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10543627.0000 - mae: 3098.8196 - val_loss: 11285577.0000 - val_mae: 3177.8743\n",
                        "Epoch 5/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 10539824.0000 - mae: 3098.2109 - val_loss: 11280846.0000 - val_mae: 3177.1101\n",
                        "Epoch 6/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 10535165.0000 - mae: 3097.4397 - val_loss: 11274208.0000 - val_mae: 3176.0410\n",
                        "Epoch 7/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10527398.0000 - mae: 3096.1860 - val_loss: 11264883.0000 - val_mae: 3174.5398\n",
                        "Epoch 8/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10516873.0000 - mae: 3094.5161 - val_loss: 11252191.0000 - val_mae: 3172.4951\n",
                        "Epoch 9/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10502154.0000 - mae: 3092.0923 - val_loss: 11234338.0000 - val_mae: 3169.6194\n",
                        "Epoch 10/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10483541.0000 - mae: 3089.0635 - val_loss: 11210422.0000 - val_mae: 3165.7620\n",
                        "Epoch 11/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10457276.0000 - mae: 3084.9033 - val_loss: 11178728.0000 - val_mae: 3160.6482\n",
                        "Epoch 12/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10424363.0000 - mae: 3079.4646 - val_loss: 11137365.0000 - val_mae: 3153.9636\n",
                        "Epoch 13/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10379842.0000 - mae: 3072.1987 - val_loss: 11084610.0000 - val_mae: 3145.4192\n",
                        "Epoch 14/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10325605.0000 - mae: 3063.4109 - val_loss: 11017388.0000 - val_mae: 3134.5007\n",
                        "Epoch 15/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10252512.0000 - mae: 3051.3577 - val_loss: 10934441.0000 - val_mae: 3120.9736\n",
                        "Epoch 16/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10160674.0000 - mae: 3036.3813 - val_loss: 10830902.0000 - val_mae: 3103.9951\n",
                        "Epoch 17/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10052261.0000 - mae: 3018.8713 - val_loss: 10707257.0000 - val_mae: 3083.5862\n",
                        "Epoch 18/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9923971.0000 - mae: 2997.3850 - val_loss: 10559421.0000 - val_mae: 3059.0000\n",
                        "Epoch 19/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9780582.0000 - mae: 2972.9333 - val_loss: 10386428.0000 - val_mae: 3030.0894\n",
                        "Epoch 20/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 9589991.0000 - mae: 2940.4558 - val_loss: 10183295.0000 - val_mae: 2996.1990\n",
                        "Epoch 21/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9398479.0000 - mae: 2905.4878 - val_loss: 9954118.0000 - val_mae: 2957.4231\n",
                        "Epoch 22/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9142442.0000 - mae: 2862.5115 - val_loss: 9692933.0000 - val_mae: 2912.4751\n",
                        "Epoch 23/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8869230.0000 - mae: 2814.0398 - val_loss: 9399204.0000 - val_mae: 2860.9448\n",
                        "Epoch 24/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8608352.0000 - mae: 2764.9326 - val_loss: 9069260.0000 - val_mae: 2801.7654\n",
                        "Epoch 25/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8249326.0000 - mae: 2699.9619 - val_loss: 8708933.0000 - val_mae: 2735.4785\n",
                        "Epoch 26/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7894579.0000 - mae: 2632.3669 - val_loss: 8314440.5000 - val_mae: 2660.6318\n",
                        "Epoch 27/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7516989.0000 - mae: 2558.3142 - val_loss: 7892222.5000 - val_mae: 2577.6792\n",
                        "Epoch 28/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7168449.0000 - mae: 2486.1182 - val_loss: 7450745.0000 - val_mae: 2487.4380\n",
                        "Epoch 29/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6710180.5000 - mae: 2387.9009 - val_loss: 6991236.0000 - val_mae: 2389.1206\n",
                        "Epoch 30/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6206148.5000 - mae: 2277.1094 - val_loss: 6525141.5000 - val_mae: 2285.9314\n",
                        "Epoch 31/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5683184.5000 - mae: 2161.9951 - val_loss: 6039738.0000 - val_mae: 2174.0164\n",
                        "Epoch 32/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5290443.0000 - mae: 2071.2166 - val_loss: 5564106.5000 - val_mae: 2064.7512\n",
                        "Epoch 33/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4828057.5000 - mae: 1953.5262 - val_loss: 5099551.5000 - val_mae: 1955.8468\n",
                        "Epoch 34/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4429286.5000 - mae: 1847.5282 - val_loss: 4657717.0000 - val_mae: 1851.0919\n",
                        "Epoch 35/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3929215.2500 - mae: 1716.1195 - val_loss: 4243496.0000 - val_mae: 1749.6213\n",
                        "Epoch 36/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3575613.7500 - mae: 1603.9279 - val_loss: 3863931.2500 - val_mae: 1658.9525\n",
                        "Epoch 37/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3260088.5000 - mae: 1519.8458 - val_loss: 3528009.2500 - val_mae: 1574.0800\n",
                        "Epoch 38/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2971305.0000 - mae: 1423.7291 - val_loss: 3232102.2500 - val_mae: 1494.7487\n",
                        "Epoch 39/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2737256.7500 - mae: 1352.3163 - val_loss: 2980916.2500 - val_mae: 1427.8232\n",
                        "Epoch 40/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2433918.7500 - mae: 1246.4075 - val_loss: 2781290.5000 - val_mae: 1369.4447\n",
                        "Epoch 41/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2227602.0000 - mae: 1167.0494 - val_loss: 2611750.2500 - val_mae: 1313.7770\n",
                        "Epoch 42/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1997652.3750 - mae: 1101.9513 - val_loss: 2471418.7500 - val_mae: 1265.6388\n",
                        "Epoch 43/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1974034.6250 - mae: 1079.3424 - val_loss: 2369541.2500 - val_mae: 1230.6252\n",
                        "Epoch 44/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1901321.3750 - mae: 1062.8409 - val_loss: 2289682.2500 - val_mae: 1201.5575\n",
                        "Epoch 45/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1866799.5000 - mae: 1021.1721 - val_loss: 2232236.2500 - val_mae: 1178.3369\n",
                        "Epoch 46/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1780486.8750 - mae: 1010.2058 - val_loss: 2187848.2500 - val_mae: 1158.1920\n",
                        "Epoch 47/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1713492.5000 - mae: 970.0735 - val_loss: 2156570.2500 - val_mae: 1142.0416\n",
                        "Epoch 48/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1683565.7500 - mae: 962.6275 - val_loss: 2133422.2500 - val_mae: 1129.6295\n",
                        "Epoch 49/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1614889.7500 - mae: 941.9924 - val_loss: 2113387.0000 - val_mae: 1118.5732\n",
                        "Epoch 50/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1513846.8750 - mae: 888.9890 - val_loss: 2099546.0000 - val_mae: 1109.3065\n",
                        "Epoch 51/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1545605.5000 - mae: 928.9531 - val_loss: 2086952.8750 - val_mae: 1101.4576\n",
                        "Epoch 52/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1520664.7500 - mae: 890.9698 - val_loss: 2071491.2500 - val_mae: 1093.1219\n",
                        "Epoch 53/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1538511.5000 - mae: 906.1865 - val_loss: 2059697.0000 - val_mae: 1087.3369\n",
                        "Epoch 54/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1526439.8750 - mae: 926.7133 - val_loss: 2050114.1250 - val_mae: 1082.2339\n",
                        "Epoch 55/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1503747.3750 - mae: 918.0624 - val_loss: 2036911.3750 - val_mae: 1077.4769\n",
                        "Epoch 56/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1437093.3750 - mae: 906.6240 - val_loss: 2024520.5000 - val_mae: 1072.1703\n",
                        "Epoch 57/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1509096.6250 - mae: 882.6642 - val_loss: 2013787.0000 - val_mae: 1068.3579\n",
                        "Epoch 58/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1398223.6250 - mae: 874.9742 - val_loss: 2000502.8750 - val_mae: 1063.3716\n",
                        "Epoch 59/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1589300.6250 - mae: 957.2559 - val_loss: 1989391.7500 - val_mae: 1058.2914\n",
                        "Epoch 60/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1458004.2500 - mae: 881.0410 - val_loss: 1977926.8750 - val_mae: 1053.0090\n",
                        "Epoch 61/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1378948.7500 - mae: 861.2918 - val_loss: 1966555.8750 - val_mae: 1049.6218\n",
                        "Epoch 62/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1424113.7500 - mae: 888.0272 - val_loss: 1955077.5000 - val_mae: 1045.8177\n",
                        "Epoch 63/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1440297.5000 - mae: 873.9393 - val_loss: 1944597.1250 - val_mae: 1043.1423\n",
                        "Epoch 64/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1439584.3750 - mae: 878.7009 - val_loss: 1935366.1250 - val_mae: 1040.8645\n",
                        "Epoch 65/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1409365.8750 - mae: 877.7559 - val_loss: 1927673.2500 - val_mae: 1037.6874\n",
                        "Epoch 66/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1415249.3750 - mae: 881.6859 - val_loss: 1917989.0000 - val_mae: 1034.4489\n",
                        "Epoch 67/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1433389.7500 - mae: 892.0804 - val_loss: 1907554.5000 - val_mae: 1031.2329\n",
                        "Epoch 68/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1400759.1250 - mae: 892.8112 - val_loss: 1895063.7500 - val_mae: 1027.5200\n",
                        "Epoch 69/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1405685.3750 - mae: 864.5765 - val_loss: 1886221.3750 - val_mae: 1024.8188\n",
                        "Epoch 70/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1461368.5000 - mae: 892.9008 - val_loss: 1876222.6250 - val_mae: 1020.9568\n",
                        "Epoch 71/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1471116.8750 - mae: 875.0653 - val_loss: 1865890.5000 - val_mae: 1017.9969\n",
                        "Epoch 72/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1322412.6250 - mae: 847.2990 - val_loss: 1854936.8750 - val_mae: 1014.9788\n",
                        "Epoch 73/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1413980.6250 - mae: 873.8406 - val_loss: 1847963.3750 - val_mae: 1013.1714\n",
                        "Epoch 74/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1358284.0000 - mae: 865.2285 - val_loss: 1838427.0000 - val_mae: 1009.6784\n",
                        "Epoch 75/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1356801.6250 - mae: 859.1160 - val_loss: 1831941.1250 - val_mae: 1006.8755\n",
                        "Epoch 76/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1382968.5000 - mae: 853.4576 - val_loss: 1824377.0000 - val_mae: 1003.4862\n",
                        "Epoch 77/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1398067.7500 - mae: 864.1094 - val_loss: 1816437.5000 - val_mae: 1000.7737\n",
                        "Epoch 78/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1292921.7500 - mae: 828.0101 - val_loss: 1807155.6250 - val_mae: 998.3013\n",
                        "Epoch 79/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1334419.3750 - mae: 839.8253 - val_loss: 1794411.8750 - val_mae: 995.6595\n",
                        "Epoch 80/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1304799.1250 - mae: 817.8594 - val_loss: 1784591.3750 - val_mae: 993.7587\n",
                        "Epoch 81/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1310122.0000 - mae: 850.8581 - val_loss: 1775929.2500 - val_mae: 993.2172\n",
                        "Epoch 82/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1404891.2500 - mae: 881.6714 - val_loss: 1765973.0000 - val_mae: 991.4155\n",
                        "Epoch 83/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1334982.0000 - mae: 864.6319 - val_loss: 1753625.5000 - val_mae: 988.8472\n",
                        "Epoch 84/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1273525.5000 - mae: 836.8381 - val_loss: 1746691.0000 - val_mae: 985.4831\n",
                        "Epoch 85/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1276461.6250 - mae: 827.3936 - val_loss: 1736225.3750 - val_mae: 982.7412\n",
                        "Epoch 86/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1251407.8750 - mae: 827.8569 - val_loss: 1727303.2500 - val_mae: 979.7998\n",
                        "Epoch 87/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1343220.6250 - mae: 842.0408 - val_loss: 1720833.5000 - val_mae: 978.3822\n",
                        "Epoch 88/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1214286.7500 - mae: 821.8702 - val_loss: 1713492.3750 - val_mae: 977.1069\n",
                        "Epoch 89/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1368668.1250 - mae: 859.7393 - val_loss: 1708482.6250 - val_mae: 973.1191\n",
                        "Epoch 90/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1287853.3750 - mae: 831.3242 - val_loss: 1706363.2500 - val_mae: 972.5835\n",
                        "Epoch 91/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1210687.5000 - mae: 803.6951 - val_loss: 1700552.1250 - val_mae: 970.9288\n",
                        "Epoch 92/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1276465.7500 - mae: 851.8054 - val_loss: 1695210.1250 - val_mae: 969.3216\n",
                        "Epoch 93/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1269208.0000 - mae: 833.3216 - val_loss: 1689363.2500 - val_mae: 966.7151\n",
                        "Epoch 94/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1207517.1250 - mae: 808.9541 - val_loss: 1683126.1250 - val_mae: 966.1362\n",
                        "Epoch 95/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1308887.8750 - mae: 833.0616 - val_loss: 1675057.3750 - val_mae: 964.9999\n",
                        "Epoch 96/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1239536.5000 - mae: 820.2159 - val_loss: 1668939.6250 - val_mae: 964.9944\n",
                        "Epoch 97/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1209082.6250 - mae: 812.2847 - val_loss: 1660699.2500 - val_mae: 961.8515\n",
                        "Epoch 98/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1266718.6250 - mae: 828.2019 - val_loss: 1654837.8750 - val_mae: 958.8804\n",
                        "Epoch 99/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1306661.1250 - mae: 839.4180 - val_loss: 1646976.0000 - val_mae: 958.4477\n",
                        "Epoch 100/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1337646.3750 - mae: 864.6432 - val_loss: 1643137.8750 - val_mae: 958.2753\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<keras.src.callbacks.history.History at 0x2230846f4d0>"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 4. Define and Train Expense Model\n",
                "def build_model(input_shape):\n",
                "    model = Sequential([\n",
                "        Dense(32, activation='relu', input_shape=(input_shape,)),\n",
                "        Dropout(0.2),\n",
                "        Dense(16, activation='relu'),\n",
                "        Dropout(0.1),\n",
                "        Dense(8, activation='relu'),\n",
                "        Dense(1) # Linear output for regression\n",
                "    ])\n",
                "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
                "    return model\n",
                "\n",
                "expense_model = build_model(X_exp_scaled.shape[1])\n",
                "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
                "\n",
                "print(\"Training Expense Model...\")\n",
                "expense_model.fit(X_exp_scaled, y_exp, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stop], verbose=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Income Model...\n",
                        "Epoch 1/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 18507336.0000 - mae: 4134.0972 - val_loss: 18368282.0000 - val_mae: 4101.2842\n",
                        "Epoch 2/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 18504418.0000 - mae: 4133.7466 - val_loss: 18364868.0000 - val_mae: 4100.8672\n",
                        "Epoch 3/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 18500710.0000 - mae: 4133.3047 - val_loss: 18360130.0000 - val_mae: 4100.2852\n",
                        "Epoch 4/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 18495832.0000 - mae: 4132.7041 - val_loss: 18353360.0000 - val_mae: 4099.4536\n",
                        "Epoch 5/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18488522.0000 - mae: 4131.8120 - val_loss: 18343532.0000 - val_mae: 4098.2456\n",
                        "Epoch 6/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18476936.0000 - mae: 4130.4004 - val_loss: 18328584.0000 - val_mae: 4096.4087\n",
                        "Epoch 7/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 18460158.0000 - mae: 4128.3730 - val_loss: 18305874.0000 - val_mae: 4093.6191\n",
                        "Epoch 8/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18435116.0000 - mae: 4125.3418 - val_loss: 18272540.0000 - val_mae: 4089.5176\n",
                        "Epoch 9/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 18396184.0000 - mae: 4120.6045 - val_loss: 18224894.0000 - val_mae: 4083.6462\n",
                        "Epoch 10/100\n",
                        "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 18345118.0000 - mae: 4114.3921 - val_loss: 18159784.0000 - val_mae: 4075.6079\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<keras.src.callbacks.history.History at 0x22309510550>"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 5. Define and Train Income Model\n",
                "income_model = build_model(X_inc_scaled.shape[1])\n",
                "\n",
                "print(\"\\nTraining Income Model...\")\n",
                "income_model.fit(X_inc_scaled, y_inc, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stop], verbose=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Models saved as dl_expense_model.keras and dl_income_model.keras\n"
                    ]
                }
            ],
            "source": [
                "# 6. Save Models\n",
                "expense_model.save('dl_expense_model.keras')\n",
                "income_model.save('dl_income_model.keras')\n",
                "\n",
                "print(\"Models saved as dl_expense_model.keras and dl_income_model.keras\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
